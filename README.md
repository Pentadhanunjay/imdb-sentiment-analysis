# IMDb Sentiment Analysis Project ğŸ¬ğŸ“Š

This project performs **Sentiment Analysis on the IMDb Movie Review Dataset** using a combination of traditional ML and modern optimization techniques.

## ğŸš€ Features Included

### âœ… Preprocessing
- HTML tag removal, punctuation cleaning, lowercasing
- Custom stopword removal (based on 50 most frequent words)
- Noisy review filtering (based on length and repetition)

### âœ… Feature Extraction
- TF-IDF vectorization with unigrams and bigrams
- Top 10,000 vocabulary features

### âœ… Modeling
- **Logistic Regression with L1** for feature selection
- **XGBoost**, tuned via **Bayesian Optimization (Optuna)**
- **Linear SVM**
- Final model is an **Ensemble (VotingClassifier)** combining all three

### âœ… Evaluation
- **Stratified 5-Fold Cross-Validation**
- F1-score as the primary metric

### âœ… Interpretability
- Shows **Top 5 misclassified reviews**
- Displays **top contributing words** to the misclassification

---

## ğŸ›  Requirements

```bash
pip install pandas scikit-learn xgboost optuna
```

Also download the IMDb dataset from [Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).

---

## ğŸ“ Files

- `imdb_sentiment_pipeline.py`: Full end-to-end pipeline script
- `IMDB Dataset.csv`: Input dataset (to be downloaded separately)

---

## ğŸ§  Insights

- Combining interpretable models (LR) with powerful learners (XGBoost, SVM) improves robustness.
- Cleaning noisy data and removing dominant stopwords has a measurable impact on performance.
- Bayesian optimization outperforms grid search for XGBoost hyperparameter tuning.

---

## ğŸ“Š Results

Achieved a **mean F1-score of ~0.88** using stratified cross-validation on filtered, optimized data.

---

## ğŸ“„ Author

Penta Dhanunjay

